{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mathai/voice_chat'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'こんにちは、このモデルはTTSをテストするためのモデルです。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-2024-08-06\")\n",
    "\n",
    "SystemPrompt = \"\"\"You are a helpful assistant in translation.\n",
    "translate language list only [\"korean\", \"japanese\", \"english\", \"arabic\"]\n",
    "you only answer output. don't show input\n",
    "Below is an example.\n",
    "\n",
    "korean translate Example:\n",
    "- input: generative model은 주어진 training data를 학습하고 training data의 분포를 따르는 유사 data를 생성하는 모델입니다.\n",
    "- output: 생성 모델은 주어진 학습 데이터를 학습하고 학습 데이터의 분포를 따르는 유사 데이터를 생성하는 모델입니다.\n",
    "\n",
    "japanese translate Example:\n",
    "- input: generative model은 주어진 training data를 학습하고 training data의 분포를 따르는 유사 data를 생성하는 모델입니다.\n",
    "- output: 生成モデルは、与えられたトレーニングデータを学習し、トレーニングデータの分布に従う類似データを生成するモデルです。\n",
    "\n",
    "english translate Example:\n",
    "- input: generative model은 주어진 training data를 학습하고 training data의 분포를 따르는 유사 data를 생성하는 모델입니다.\n",
    "- output: A generative model is a model that learns given training data and generates similar data that follows the distribution of the training data.\n",
    "\n",
    "arabic translate Example:\n",
    "- input: generative model은 주어진 training data를 학습하고 training data의 분포를 따르는 유사 data를 생성하는 모델입니다.\n",
    "- output: النموذج التوليدي هو نموذج يتعلم بيانات التدريب المعطاة ويولد بيانات مماثلة تتبع توزيع بيانات التدريب.\n",
    "\n",
    "Now, look at the Question and Language and translate the Question into Language.\n",
    "\n",
    "Question: {question}\n",
    "Language: {language}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    SystemPrompt\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"question\": RunnablePassthrough(), \"language\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"안녕하세요, 이 모델은 tts를 test하기 위한 모델 입니다.\"\n",
    "language = \"japanese\"\n",
    "\n",
    "chain.invoke({\"question\":question, \"language\": language})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
